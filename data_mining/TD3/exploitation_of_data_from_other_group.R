# Clean up the mess
rm(list=ls())
graphics.off()

# Load data
load(file="\\Users\\maeli\\Documents\\INSA\\4A\\Taltech\\data_mining\\TD3\\data_training\\gaussians2.RData")
x<-data_matrix

## --- DISTANCE --- ##
get_distance <-function(element1,element2,metricf){
  # return distance btw ele1 and ele2 according to metricf
  dimensions=length(element1)
  sqd<-matrix(, dimensions,1)
  
  # EUCLIDIAN
  if (metricf == "Euclidean") {
    for (i in seq(along = element1)) {
      sqd[i] <- (element1[i] - element2[i])^2
    }
    dist <- sqrt(colSums(sqd))
  }
  
  # MANHATTAN
  if (metricf == "Manhattan") {
    for (i in seq(along = element1)) {
      sqd[i] <- abs(element1[i] - element2[i])
    }
    dist <- colSums(sqd)
  }
  
  
  # MINKOWSKI
  if (metricf == "Minkowski") {
    p <- 1
    for (i in seq(along = element1)) {
      sqd[i] <- (abs(element1[i] - element2[i]))^p
    }
    dist <- (colSums(sqd))^(1 / p)
  }
  
  # MAHALANOBIS
  if (metricf == "Mahalanobis") {
    sub_matrix <- element1 - element2
    cov_matrix <- cov(element1, element2)
    dist <- sqrt(t(sub_matrix) * solve(cov_matrix) * sub_matrix)
    
  }
  
  # COSINE
  if (metricf == "Cosine") {
    norm1 <- sqrt(sum(element1))
    norm2 <- sqrt(sum(element2))
    dist <- (dot(element1, element2)) / (norm1 * norm2)
  }
  
  # CAMBERRA
  if (metricf == "Camberra") {
    for (i in seq(along = element1)) {
      sqd[i] <- (abs(element1[i] - element2[i])) / (abs(element1[i]) + abs(element2[i]))
    }
    dist <- colSums(sqd)
  }
  return(dist)
}
## --- K MEANS --- ##
is_converging <- function(old_centroids, new_centroids, dataset){
  
  #COULD BE CHANGED TO LOSS MINIMIZATION
  #Return true if converge or false if a centroid style move
  last_column = ncol(dataset)
  K = max(dataset[,last_column])
  for(k in seq(along=1:K))
  {
    #value <- TRUE
    current_distance <- get_distance(old_centroids[k,], new_centroids[k,], "Euclidean")
    #cat("[ ", k, " ] Distance is ",current_distance, "\n")
    if(!(current_distance == 0)){ return(FALSE) }
    #now juste keep the last value a 0 so need to do an array to keep the for all
  }
  return(TRUE)
}

update_centroids <- function(dataset, dimension){
  last_column = ncol(dataset)
  K = max(dataset[,last_column])
  centroids <- matrix(, nrow=K, ncol=last_column-1)
  for (k in seq(along=1:K)){
    cluster <- dataset[dataset[, last_column] == k,]
    cluster <- cluster[,1:2]
    centroids[k,] = colMeans(cluster)
    print(centroids)
  }
  return(centroids)
}

get_label <- function(dataset, centroids){
  for (i in seq(along=1:nrow(dataset))){
    temp_dist <- matrix(,nrow=nrow(centroids))
    for (j in seq(along=1:nrow(centroids))){
      temp_dist[j,] = get_distance(centroids[j,], dataset[i,1:2], "Euclidean")
    }
    dataset[i, 3] = which.min(temp_dist) #this is the place we stock the label in
  }
  return(dataset)
}

# We prepare the data : we split between the training set and the validation set
sample_size <- floor(0.7 * nrow(x))
data_dimensionality = ncol(x)
#set.seed(123) # seed is set so we can reproduce it
train_ind <- sample(seq_len(nrow(x)), size = sample_size)
train_set <- x[train_ind, ]
test <- x[-train_ind, ]
train <- train_set[,1:2] # just to assure that we have two columns
# Starting k means, with k=3 to begin with
K <- 6
centroids <- matrix(, nrow=K,ncol=data_dimensionality)
for (k in seq(along=1:K)){
  centroids[k,] = runif(2)
  print(centroids[k,])
}
# cat("Initial centroids are: ", centroids)

# Label column
aux_column <- matrix(0, nrow(train_set))
train_set = cbind(train_set,aux_column)
i <- 1
# Iteration : need a convergence criteria
#for (i in seq(along=1:40)){
repeat{
  i <- i+1
  #cat("Step: ", i)
  train_set <- get_label(train_set, centroids)
  old_centroids <- centroids
  centroids <- update_centroids(train_set, 2)
  #cat(" Centroids have been updated: ", centroids)
  plot(train_set[,1], train_set[,2], type="p", col=train_set[,3])
  points(centroids, col="midnightblue", type="p")
  par(new=TRUE)
  cat("Iteration : ",i, "\n")
  if(is_converging(old_centroids, centroids,train_set)) {break};
}
  
# cat(" Centroids are updated: ", centroids)
graphics.off()
plot(train_set[, 1], train_set[, 2], type='p', col=train_set[,3])
par(new=TRUE)
points(centroids[,1], centroids[,2], col="red", type="p")
## --- VALIDATION --- ##

#personnal function
silhouette <- function(nb_cluster, dataset){
  silhouette_values <- matrix(,0,2)
  for (k in seq(along=1:nb_cluster)){
  #k is the cluster we are studying
  current_cluster_points <- dataset[dataset[,3]==k,]
  other_cluster_points <- dataset[dataset[,3]!=k,]
  #Calculating average distance
  n_row_current_clstr <- nrow(current_cluster_points)
  #For each point of the dataset (regrouped by cluster)
    for(current_point in seq(along=1:n_row_current_clstr))
    {
      #SAME CLUSTER AVERAGE DIST
      average_dist_same_cluster <- 0
      for(other_point in seq(along=1:n_row_current_clstr)){
        if(other_point != current_point){
          dist <- get_distance(dataset[current_point,], dataset[other_point,], "Cosine")
          average_dist_same_cluster <- average_dist_same_cluster + dist
        }
      }
      average_dist_same_cluster <- average_dist_same_cluster / n_row_current_clstr
      #OTHER CLUSTER MIN AVERAGE DISTANCE
      average_dist_other_cluster <- vector()
      dist_cluster_to_compute <- 0
      for(other_k in seq(1:nb_cluster))
      {
        if(other_k != k){
          cluster_to_compute <- dataset[dataset[,3]==other_k,]
          for(other_point in seq(along=1:nrow(cluster_to_compute)))
          {
            dist <- get_distance(dataset[current_point,], dataset[other_point,], "Euclidean")
            dist_cluster_to_compute <- dist_cluster_to_compute + dist
          }
          dist_cluster_to_compute <- dist_cluster_to_compute / nrow(other_cluster_points)
          average_dist_other_cluster <- c(average_dist_other_cluster, dist_cluster_to_compute)
          
        }
      }
      #SILHOUETTE FOR THIS POINT
      min_dist_other_clstr <- min(average_dist_other_cluster)
      s_point <- (min_dist_other_clstr-average_dist_same_cluster)/max(min_dist_other_clstr,average_dist_same_cluster)
      silhouette_values <- rbind(silhouette_values, c(s_point,k))
    }
  
  }
  return(silhouette_values)  
}


#sil <- silhouette(K, train_set)
#plot(sil[,1],sil[,2], main="Silhouette")
save(train_set,file="\\Users\\maeli\\Documents\\INSA\\4A\\Taltech\\data_mining\\TD3\\data_training\\kmeans\\gaussians2.RData" )
print("Done")